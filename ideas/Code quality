Measuring code quality through entropy

Entropy

Physical sciences - The amount of randomness in the system

Information theory In information theory, entropy is the average amount of information contained in each message received

Software - The amount of information contained in parameters to a function or procedure


eg

isTrue(boolean a, boolean b, boolean c, boolean d)

  return a && b && c && d;

The amount of entropy here is 2 ^ 4 = 16

Entropy is directly proportional to the number of test cases necessary to test the function. Higher the entropy, greater the probability that some cases are missed

Entropy with non boolean variables

sum(long a, long b)

  return a + b;

Here the entropy = Numberofunique values for long ^ 2

For all practical purposes, this is a very large value. Since the goal of this metric is comparison, we can use asymptotic notation.

O(N^2) where N is the number of unique values for the long data type.

Procedural code does not lead to reduction in entropy

   eg sum(long a, long b, long c){
     return sum(a, b) + c;
   }

Entropy can be reduced using data abstractions. In fact reduction in entropy is an essential quality for a decomposition to be called an abstraction

OngoingSum sum(OngoingSum sum, c){

}

@Immutable
OngoingSum {

   private final long value;

   public OngoingSum(long a, long b)

   public OngoingSum(long b)

   public void longValue()
}

Data abstractions help limit the length of the flows

  This makes it more testable

  More decoupled - if a flow is long, bugs in the lines with lower numbers can affect bugs in the lines which higher numbers

eg.

function(int a){
  if(figureoutSomething()){

  }
  // Do Something
}

can be rewritten as

function boolean processing(CustomClass a){
  if(a.doesSomePropertyMatch()){
    return true.
  }
  return  false;
}

In the second case, care must be taken that CustomClass is an abstract representation and just not hiding the implementation of figureOutSomething

This can be identified by the fact that you may have to mock CustomClass for tests

This is better than cyclomatic complexity. Cyclomatic complexity only counts the number of code flows, and completely ignores
expression level complexity.

For example, the complexity of |(a - 2 * x)| % (10 * b) where scenarios like a > 2 * x are ignored by cyclomatic complexity.

The same code with correct data abstractions will look like

 totalCoveredDistance = |(a - 2x)|;
 totalAllowd = (10 * b);
 totalCoveredDistance % totalAllowed

Here the entropy of individual statements are much lesser than the original.
--
In the second case though, the client has the responsibility for mapping integer to CustomClass. But ideally we wont want that.
Hence we will use programmable semicolons (monads). The bind function of the monad will take care of converting the integer to CustomClass.
Once we do this, we need not have boiler plate code in the clients.

So the caller of the above function will now look like

{
  Function<CustomClass, Boolean> processing = new Function<>();
  return new CustomClassInterpretation<Int>().elevate(a).bind(processing).value();
}

Here the elevate function takes an integer converts it into an CustomClassInterpretation object (it is elevating int to CustomClassInterpretation<Int>)

How is this different from

{
   processing(mapper(a));
}

"Type elevation helps to translate the meaning of a function from a simple type to an elevated type there by greatly enhancing the reusability of the function"


Consider the following object oriented code

Integer {

  // Adds value the current value
  public add(int value){

  }
}

and if you have a list of integers, you would like to add 2 to each element in the list, you do

for(int element : list){
  element.add(2);
}

and if you have a list of integers, you would like to multiply 2 to each element in the list, you do

for(int element : list){
  element.multiply(2);
}

These two snippets of code cannot be defined in the List class as the type of the elements in the list class is parameterized

But in a monadic way, you can do this

function add(int value, int a);

function multiply(int value, int a);

The List monad will now have bind function which applies a given lambda, applies it to all the elements in the list returning a list

List<A>

  List<B> each(Lambda<A,B> lambda)


and then, you can "reuse" add and subtract as

bind([1, 2], add(3))

bind([1, 2], multiply(2))

Now, let us consider two dimensional lists, this is how the code will look

bind([[1, 2], [2, 3]], add(3))

To make this possible, the paradigm should support

  1. Monads (That provide the bind method)

  2. Partial evaluations

TODO: Figure out how to write bind for maps
